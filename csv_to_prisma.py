import os
import glob
import pandas as pd
import argparse
from datetime import datetime
import re
import json

INPUT_DIR = 'input'
SCHEMA_DIR = 'schemas'

# Utility to find the latest CSV file in the input directory
def get_latest_csv(input_dir=INPUT_DIR):
    csv_files = glob.glob(os.path.join(input_dir, '*.csv'))
    if not csv_files:
        raise FileNotFoundError('No CSV files found in the input directory.')
    latest_file = max(csv_files, key=os.path.getmtime)
    return latest_file

def to_snake_case(name):
    # Replace non-alphanumeric (except digits) with underscores, lowercase, collapse multiple underscores
    name = re.sub(r'[^a-zA-Z0-9]+', '_', name)
    name = re.sub(r'([a-z0-9])([A-Z])', r'\1_\2', name)  # Add underscore before capital letters
    name = name.lower()
    name = re.sub(r'_+', '_', name)  # Collapse multiple underscores
    name = name.strip('_')
    return name

# Utility to generate a Prisma schema from a CSV file
def generate_prisma_schema(csv_path, schema_dir=SCHEMA_DIR):
    df = pd.read_csv(csv_path, nrows=100)  # Read a sample for type inference
    column_mapping = {}
    model_name = os.path.splitext(os.path.basename(csv_path))[0].capitalize()
    # Add datasource and generator block at the top
    prisma_header = '''// database
datasource db {
  provider = "postgres"
  url      = env("DATABASE_URL")
}

// generator
generator client {
  provider             = "prisma-client-py"
  recursive_type_depth = 5
}
'''
    schema_lines = [f'model {model_name} {{']
    # Add autogenerated UUID id field
    schema_lines.append('  id String @id @default(uuid())')
    for col in df.columns:
        col_snake = to_snake_case(col)
        dtype = infer_prisma_type_from_data(df[col])
        schema_lines.append(f'  {col_snake} {dtype}')
        column_mapping[col] = col_snake
    schema_lines.append('}')

    # SCD2 model
    scd2_model_name = f'{model_name}History'
    scd2_lines = [f'model {scd2_model_name} {{']
    scd2_lines.append('  surrogate_key String @id @default(uuid())')
    for col in df.columns:
        col_snake = to_snake_case(col)
        dtype = infer_prisma_type_from_data(df[col])
        scd2_lines.append(f'  {col_snake} {dtype}')
    scd2_lines.append('  start_date DateTime')
    scd2_lines.append('  end_date DateTime?')
    scd2_lines.append('  is_current Boolean')
    scd2_lines.append('}')

    os.makedirs(schema_dir, exist_ok=True)
    schema_path = os.path.join(schema_dir, f'{model_name}.prisma')
    with open(schema_path, 'w') as f:
        f.write(prisma_header)
        f.write('\n'.join(schema_lines))
        f.write('\n\n')
        f.write('\n'.join(scd2_lines))
    # Write column mapping to JSON with extra params
    mapping_path = os.path.join(schema_dir, f'{model_name}_column_mapping.json')
    mapping_json = {
        "source_csv": os.path.abspath(csv_path),
        "target_table": model_name,
        "target_history_table": f"{model_name}History",
        "column_mapping": column_mapping
    }
    with open(mapping_path, 'w') as f:
        json.dump(mapping_json, f, indent=2)
    print(f'Prisma schema (with SCD2) written to {schema_path}')
    print(f'Column mapping JSON written to {mapping_path}')
    return schema_path

def infer_prisma_type_from_data(series):
    # Try to infer boolean
    lower = series.dropna().astype(str).str.lower()
    if lower.isin(['true', 'false', 'yes', 'no', '0', '1']).all():
        return 'Boolean'
    # Try to infer integer (only if all non-null values are numeric and not strings with non-numeric chars)
    try:
        as_int = pd.to_numeric(series, errors='coerce')
        if as_int.notnull().all() and series.dropna().apply(lambda x: str(x).strip().isdigit()).all():
            if as_int.dropna().apply(float.is_integer).all():
                return 'Int'
    except Exception:
        pass
    # Try to infer float (only if all non-null values are numeric and not all are integers)
    try:
        as_float = pd.to_numeric(series, errors='coerce')
        if as_float.notnull().all() and not as_float.dropna().apply(float.is_integer).all():
            return 'Float'
    except Exception:
        pass
    # Try to infer datetime (try common formats first to avoid warning)
    date_formats = [
        '%Y-%m-%d', '%d-%m-%Y', '%m/%d/%Y', '%Y/%m/%d', '%d/%m/%Y',
        '%Y-%m-%d %H:%M:%S', '%d-%m-%Y %H:%M:%S', '%m/%d/%Y %H:%M:%S', '%Y/%m/%d %H:%M:%S', '%d/%m/%Y %H:%M:%S'
    ]
    for fmt in date_formats:
        try:
            as_date = pd.to_datetime(series, errors='coerce', format=fmt)
            if as_date.notnull().sum() > 0 and as_date.notnull().sum() / len(series) > 0.5:
                return 'DateTime'
        except Exception:
            pass
    # Fallback: try without format, but suppress warning
    import warnings
    with warnings.catch_warnings():
        warnings.simplefilter('ignore', UserWarning)
        try:
            as_date = pd.to_datetime(series, errors='coerce')
            if as_date.notnull().sum() > 0 and as_date.notnull().sum() / len(series) > 0.5:
                return 'DateTime'
        except Exception:
            pass
    # Default to String
    return 'String'

# Utility to execute schema files (create tables in DB)
def execute_schema(schema_path, db_url):
    # This is a placeholder for actual Prisma migration logic
    # In practice, you would copy the schema to schema.prisma and run `prisma migrate dev`
    print(f'Would apply schema {schema_path} to DB at {db_url}')
    os.system(f"cp {schema_path} schema.prisma && npx prisma@5.17.0 migrate dev --name init") 
    # --url {db_url}

def main():
    parser = argparse.ArgumentParser(description='CSV to Prisma schema utility')
    subparsers = parser.add_subparsers(dest='command')

    gen_parser = subparsers.add_parser('generate-schema', help='Generate Prisma schema from latest CSV')
    gen_parser.add_argument('--input-dir', default=INPUT_DIR)
    gen_parser.add_argument('--schema-dir', default=SCHEMA_DIR)
    gen_parser.add_argument('--schema-path', default=os.getenv('SCHEMA_PATH'))

    exec_parser = subparsers.add_parser('execute-schema', help='Execute schema file on DB')
    exec_parser.add_argument('--schema-path', default=os.getenv('SCHEMA_PATH'))
    exec_parser.add_argument('--db-url', default=os.getenv('DATABASE_URL'))

    args = parser.parse_args()

    if args.command == 'generate-schema':
        latest_csv = get_latest_csv(args.input_dir)
        schema_dir = args.schema_dir
        generate_prisma_schema(latest_csv, schema_dir)
    elif args.command == 'execute-schema':
        execute_schema(args.schema_path, args.db_url)
    else:
        parser.print_help()

if __name__ == '__main__':
    try:
        from dotenv import load_dotenv
        load_dotenv()
    except ImportError:
        print('Warning: python-dotenv is not installed. .env file will not be loaded.')
    main()
